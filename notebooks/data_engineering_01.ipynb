{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "As we say from the `data_exploration` file, the initial set of data contains a lot of `NaN` values. For now, we'll impute using `sklearn.impute.KNNImputer`, but we will experiment with other methods in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "df = pd.read_csv('../data/raw/dengue_features_train.csv')\n",
    "df_labels = pd.read_csv('../data/raw/dengue_labels_train.csv')\n",
    "df_test = pd.read_csv('../data/raw/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our impute function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_df(df):\n",
    "    imputer = KNNImputer()\n",
    "    for column in df.columns:\n",
    "        if df[column].isna().sum() != 0:\n",
    "            df[column] = imputer.fit_transform(df[[column]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are linearly dependent. This is shown in the correlation matrix in the `data_exploration` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = impute_df(df)\n",
    "df_labels = impute_df(df_labels)\n",
    "df_test = impute_df(df_test)\n",
    "\n",
    "df.drop(labels=['precipitation_amt_mm', 'reanalysis_specific_humidity_g_per_kg', 'reanalysis_min_air_temp_k'], axis=1, inplace=True)\n",
    "df_test.drop(labels=['precipitation_amt_mm', 'reanalysis_specific_humidity_g_per_kg', 'reanalysis_min_air_temp_k'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/clean/full/dengue_features_train.csv', index=False)\n",
    "df_labels.to_csv('../data/clean/full/dengue_labels_train.csv', index=False)\n",
    "\n",
    "df_test.to_csv('../data/clean/full/dengue_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define new .csv's for each of the cities, for easier data modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_features = df[df['city'] == 'sj']\n",
    "iq_train_features = df[df['city'] == 'iq']\n",
    "\n",
    "sj_train_labels = df_labels[df_labels['city'] == 'sj']\n",
    "iq_train_labels = df_labels[df_labels['city'] == 'iq']\n",
    "\n",
    "sj_test_features = df_test[df_test['city'] == 'sj']\n",
    "iq_test_features = df_test[df_test['city'] == 'iq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_features.to_csv('../data/clean/sj/sj_train_features.csv', index=False)\n",
    "sj_train_labels.to_csv('../data/clean/sj/sj_train_labels.csv', index=False)\n",
    "\n",
    "iq_train_features.to_csv('../data/clean/iq/iq_train_features.csv', index=False)\n",
    "iq_train_labels.to_csv('../data/clean/iq/iq_train_labels.csv', index=False)\n",
    "\n",
    "sj_test_features.to_csv('../data/clean/sj/sj_test_features.csv', index=False)\n",
    "iq_test_features.to_csv('../data/clean/iq/iq_test_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
